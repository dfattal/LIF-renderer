# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

LIF Renderer is a THREE.js library that renders Light Field Images (RGB+Depth pairs) as 3D reconstructions using holographic projector rendering. The core rendering technique transforms 2D pixels into instanced 3D quads positioned using camera intrinsics and inverse depth maps.

## Development Commands

```bash
# Start development server with demo (http://localhost:8080)
npm run dev

# Build library for distribution (ES modules + CJS + type definitions)
npm run build

# Build library only (without types)
npm run build:lib

# Build TypeScript declarations only
npm run build:types

# Clean build artifacts and dependencies
npm run clean
```

## Architecture

### Core Components

**HoloProjector** (src/HoloProjector.ts)
- THREE.Object3D subclass representing a holographic projector in 3D space
- Loads RGB and depth textures (URLs or direct THREE.Texture objects)
- Stores camera intrinsics (fx, fy, cx, cy) and inverse depth range (min, max, baseline)
- Auto-injection mechanism: When added to scene, automatically injects HoloRenderer if none exists (via detection mesh with onBeforeRender hook)
- Includes frustum visualization helper (toggle with `.frustumHelper.visible`)

**HoloRenderer** (src/HoloRenderer.ts)
- THREE.Mesh subclass that performs the actual rendering
- Uses instanced rendering: One quad instance per pixel in the projector's image
- onBeforeRender: Scans scene for all HoloProjector instances and renders them
- Currently renders first projector found (multiple projector support requires rendering separately)
- Uses custom GLSL shaders (holoVertex.glsl, holoFragment.glsl) for 3D reconstruction

### Rendering Pipeline

1. **Vertex Shader** (src/shaders/holoVertex.glsl)
   - Each instance (gl_InstanceID) maps to one pixel in the source image
   - Samples depth texture to get inverse depth value (0=far, 1=near)
   - Converts inverse depth to actual depth: `Z = baseline / invZ`
   - Reconstructs 3D position using camera intrinsics: `X = (x - cx) * Z / fx`
   - Transforms position from projector space → world space → view space → clip space
   - Sizes quad billboard to match pixel footprint at that depth (pointSize=1.0 = perfect tiling)
   - Discards points behind camera

2. **Fragment Shader** (src/shaders/holoFragment.glsl)
   - Renders square quads with soft edges (10% edge softening)
   - Applies color from RGB texture
   - Uses premultiplied alpha for depth blending

3. **Depth Encoding**
   - Depth maps store **inverse depth** (disparity): 0=furthest, 1/255=closest
   - Physical depth calculated as: `depth = baseline / invZ`
   - Baseline defaults to 1.0 but should match stereo camera baseline (e.g., 0.045m)

### Project Structure

```
src/
  index.ts              # Main export file
  HoloProjector.ts      # Projector object with auto-injection
  HoloRenderer.ts       # Renderer with instanced quad geometry
  shaders/
    holoVertex.glsl     # Per-pixel 3D reconstruction
    holoFragment.glsl   # Square rendering with soft edges
  types/
    glsl.d.ts          # TypeScript declarations for .glsl imports

index.html             # Demo application with orbit controls
public/assets/         # Sample RGB+Depth data (SFMoMA restaurant)
```

## Key Technical Details

### Camera Intrinsics
- Define how pixels map to 3D rays: `fx, fy` (focal length in pixels), `cx, cy` (principal point)
- Typical value: `fx = fy = 0.78 * imageWidth` for ~60° FOV
- Principal point usually at image center: `cx = width/2, cy = height/2`

### Inverse Depth Range
- `min`: Inverse depth of closest point (e.g., 0.09 = 1/11.1m with baseline=1.0)
- `max`: Inverse depth of furthest point (e.g., 0.0001 = 1/10000m)
- `baseline`: Stereo baseline in meters (optional, default 1.0)

### Auto-Injection
When a HoloProjector is added to a scene:
1. Detection mesh (empty geometry) is created as child
2. On first render, onBeforeRender checks if scene has HoloRenderer
3. If not found, creates and adds HoloRenderer(pointSize=1.0) to scene
4. Detection mesh removes itself after injection

### Build Configuration
- **Library mode**: Outputs ES module (lif-renderer.module.js) and CJS (lif-renderer.cjs.js)
- **Entry**: src/index.ts
- **External**: three.js (peer dependency, not bundled)
- **Type definitions**: Generated by vite-plugin-dts + tsc (dist/types/)
- **GLSL imports**: Handled by vite-plugin-glsl (inline shaders as strings)

## Demo Application

The demo (index.html) includes:
- Sample scene loading (SFMoMA restaurant: 1280x800 RGB+depth)
- Interactive camera controls (WASD movement, click+drag rotation)
- Double-click orbit mode with raycast point picking
- Frustum visualization toggle (F key)
- FPS and point count display

The raycast function (lines 173-224) demonstrates how to map mouse coordinates back to 3D points in the reconstruction by sampling the depth texture and applying inverse projection.
